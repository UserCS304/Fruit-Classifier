{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2221bc-7915-4b9c-8550-9755534ba6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\computer_bsc\\anaconda3\\envs\\362-env\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\computer_bsc\\anaconda3\\envs\\362-env\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Loaded 50 apple images\n",
      "Loaded 49 orange images\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"D:/6610210304\"\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "base_dir = \"D:/6610210304\"\n",
    "apple_images = load_images_from_folder(os.path.join(base_dir, \"apple\"))\n",
    "orange_images = load_images_from_folder(os.path.join(base_dir, \"orange\"))\n",
    "\n",
    "print(f\"Loaded {len(apple_images)} apple images\")\n",
    "print(f\"Loaded {len(orange_images)} orange images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc43bc2-3eab-42b3-aacb-ce714018416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might want to resize or preprocess these images later\n",
    "# Example: resize to a common size (e.g., 100x100)\n",
    "resized_apple_images = [cv2.resize(img, (100, 100)) for img in apple_images]\n",
    "resized_orange_images = [cv2.resize(img, (100, 100)) for img in orange_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b410afd2-fe33-4ac9-a99f-9f1aee55269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened apple features shape (first image): (30000,)\n",
      "Flattened orange features shape (first image): (30000,)\n"
     ]
    }
   ],
   "source": [
    "# Flatten the resized images into feature vectors\n",
    "apple_features = [img.flatten() for img in resized_apple_images]\n",
    "orange_features = [img.flatten() for img in resized_orange_images]\n",
    "\n",
    "print(f\"Flattened apple features shape (first image): {apple_features[0].shape}\")\n",
    "print(f\"Flattened orange features shape (first image): {orange_features[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb870a1-e2a1-472e-bb9a-967bcfa70a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\computer_bsc\\anaconda3\\envs\\362-env\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\computer_bsc\\anaconda3\\envs\\362-env\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\computer_bsc\\anaconda3\\envs\\362-env\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\computer_bsc\\anaconda3\\envs\\362-env\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\computer_bsc\\anaconda3\\envs\\362-env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Training features shape: (79, 30000)\n",
      "Testing features shape: (20, 30000)\n",
      "Training labels shape: (79,)\n",
      "Testing labels shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create labels: 0 for apple, 1 for orange\n",
    "apple_labels = [0] * len(apple_features)\n",
    "orange_labels = [1] * len(orange_features)\n",
    "\n",
    "# Combine features and labels\n",
    "all_features = apple_features + orange_features\n",
    "all_labels = apple_labels + orange_labels\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(all_features)\n",
    "y = np.array(all_labels)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing labels shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1bddd18-5ee0-47ff-8fc9-734edb292d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        12\n",
      "           1       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.90      0.90      0.90        20\n",
      "weighted avg       0.90      0.90      0.90        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train the SVM Classifier\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b19246a2-4560-4855-8aae-908c7d3bf163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to svm_image_classifier_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "filename = 'svm_image_classifier_model.pkl'\n",
    "joblib.dump(svm_model, filename)\n",
    "\n",
    "print(f\"Model saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e5917ab-ed15-4b57-a838-44ec498ec728",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstreamlit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mst\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "\n",
    "import streamlit as st\n",
    "import joblib\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2  # <--- FIXED: Must import cv2 if you use cv2 functions\n",
    "\n",
    "# --- Load Model ---\n",
    "try:\n",
    "    with open(\"svm_image_classifier_model.pkl\", \"rb\") as f:\n",
    "        model = joblib.load(f)\n",
    "except FileNotFoundError:\n",
    "    st.error(\"Error: Model file 'svm_image_classifier_model.pkl' not found. Please run the training steps first.\")\n",
    "    model = None\n",
    "\n",
    "# Define the classification dictionary \n",
    "class_dict = {\n",
    "    0: \"à¹à¸­à¸›à¹€à¸›à¸´à¹‰à¸¥ (Apple)\", \n",
    "    1: \"à¸ªà¹‰à¸¡ (Orange)\"\n",
    "}\n",
    "\n",
    "# --- UI Layout ---\n",
    "st.title(\"Fruit Classifier ðŸŽðŸŠ\")\n",
    "st.write(\"à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¸£à¸¹à¸›à¸ à¸²à¸žà¹€à¸žà¸·à¹ˆà¸­à¸—à¸³à¸™à¸²à¸¢à¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™ à¹à¸­à¸›à¹€à¸›à¸´à¹‰à¸¥ à¸«à¸£à¸·à¸­ à¸ªà¹‰à¸¡\") \n",
    "\n",
    "uploaded_file = st.file_uploader(\n",
    "    \"Choose an image...\", \n",
    "    type=[\"jpg\", \"png\", \"jpeg\"]\n",
    ")\n",
    "\n",
    "# --- Prediction Logic ---\n",
    "if uploaded_file is not None and model is not None:\n",
    "    # Load and Display Image\n",
    "    # Convert(\"RGB\") is important for consistency\n",
    "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
    "    st.image(image, caption='Uploaded Image', use_container_width=True)\n",
    "\n",
    "    if st.button(\"Predict\"):\n",
    "        # --- Preprocess ---\n",
    "        \n",
    "        # Convert PIL Image (RGB) to numpy array\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        # Convert RGB array to BGR format if the model was trained using cv2.imread (BGR)\n",
    "        # BGR is the standard for OpenCV loading\n",
    "        image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR) # <--- FIXED: Corrected GBR to BGR\n",
    "        \n",
    "        # Resize image to 100x100\n",
    "        image_resized = cv2.resize(image_array, (100, 100))\n",
    "        \n",
    "        # Flatten to 1D and reshape for model input\n",
    "        image_flatten = image_resized.flatten().reshape(1, -1)\n",
    "\n",
    "        # --- Predict ---\n",
    "        try:\n",
    "            prediction = model.predict(image_flatten)[0]\n",
    "            prediction_name = class_dict[prediction]\n",
    "\n",
    "            st.success(f\"**à¸œà¸¥à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢ (Prediction Result):** **{prediction_name}**\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error during model prediction: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa516abb-f0bd-4703-9537-cdd088a79bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (362-env)",
   "language": "python",
   "name": "362-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
